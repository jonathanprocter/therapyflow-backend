Excellent. Below is the complete, drop-in stub set to integrate the full pipeline with clean contracts, idempotency, and clear TODOs for the agent. Paths assume an Express + TypeScript + Drizzle + Postgres setup similar to your other project. Adjust minor imports to match your app bootstrap.

Conventions and defaults
- Provider priority: OpenAI primary (env OPENAI_API_KEY), Anthropic fallback (env ANTHROPIC_API_KEY)
- Timezone: America/New_York
- Prompt ID: care_notes_v1
- JSON-only responses from AI; one retry on JSON parse failure

1) Schema: shared/schema.ts additions
Add these table definitions (or migrate via your preferred migration tool).

TypeScript
// shared/schema.ts (additions)
import { pgTable, text, jsonb, timestamp, integer, boolean, varchar } from "drizzle-orm/pg-core";
import { sql } from "drizzle-orm";

export const documents = pgTable("documents", {
  id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
  clientId: varchar("client_id"),
  appointmentDate: text("appointment_date"), // YYYY-MM-DD
  filename: text("filename"),
  mimeType: text("mime_type"),
  text: text("text"),
  meta: jsonb("meta"),
  status: text("status").default("uploaded"), // uploaded | parsed | error
  createdAt: timestamp("created_at").default(sql`now()`),
  updatedAt: timestamp("updated_at").default(sql`now()`),
});

export const aiDocumentResults = pgTable("ai_document_results", {
  id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
  documentId: varchar("document_id").notNull(),
  promptId: text("prompt_id").notNull(), // 'care_notes_v1'
  model: text("model"),
  entities: jsonb("entities"),
  extractions: jsonb("extractions"),
  summary: text("summary"),
  recommendations: jsonb("recommendations"),
  confidence: integer("confidence"), // 0-100 for convenience
  createdAt: timestamp("created_at").default(sql`now()`),
});

export const semanticEdges = pgTable("semantic_edges", {
  id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
  documentId: varchar("document_id").notNull(),
  from: text("from").notNull(), // e.g., symptom:insomnia
  to: text("to").notNull(),     // e.g., recommendation:CBT-I
  relation: text("relation").notNull(), // treats, causes, suggests
  weight: integer("weight"), // optional 0-100
  createdAt: timestamp("created_at").default(sql`now()`),
});

export const appointments = pgTable("appointments", {
  id: varchar("id").primaryKey().default(sql`gen_random_uuid()`),
  clientId: varchar("client_id").notNull(),
  date: text("date").notNull(), // YYYY-MM-DD
  time: text("time"), // HH:MM
  externalRef: text("external_ref"),
  notesId: varchar("notes_id"),
  createdAt: timestamp("created_at").default(sql`now()`),
});

2) Storage helpers: server/storage-extensions.ts
These encapsulate DB logic and idempotency checks.

TypeScript
// server/storage-extensions.ts
import { db } from "./data/db"; // adjust to your actual db export
import { documents, aiDocumentResults, semanticEdges, appointments } from "../shared/schema";
import { eq, and } from "drizzle-orm";

export async function createDocument({ clientId, appointmentDate, filename, mimeType, meta }:{
  clientId: string; appointmentDate: string; filename: string; mimeType: string; meta?: any;
}) {
  const [row] = await db.insert(documents).values({
    clientId, appointmentDate, filename, mimeType, meta, status: "uploaded"
  }).returning();
  return row;
}

export async function updateDocumentParsed(documentId: string, text: string, meta?: any) {
  const [row] = await db.update(documents)
    .set({ text, status: "parsed", meta, updatedAt: new Date() })
    .where(eq(documents.id, documentId))
    .returning();
  return row;
}

export async function getDocument(documentId: string) {
  const [row] = await db.select().from(documents).where(eq(documents.id, documentId));
  return row;
}

export async function getAIResult(documentId: string, promptId: string) {
  const rows = await db.select().from(aiDocumentResults)
    .where(and(eq(aiDocumentResults.documentId, documentId), eq(aiDocumentResults.promptId, promptId)));
  return rows || null;
}

export async function saveAIResult({ documentId, promptId, model, entities, extractions, summary, recommendations, confidence }:{
  documentId: string; promptId: string; model?: string;
  entities: any; extractions: any; summary: string; recommendations: string[]; confidence: number;
}) {
  const existing = await getAIResult(documentId, promptId);
  if (existing) return existing;
  const [row] = await db.insert(aiDocumentResults).values({
    documentId, promptId, model, entities, extractions, summary, recommendations, confidence: Math.round(confidence * 100)
  }).returning();
  return row;
}

export async function upsertAppointment({ clientId, date, time, notesId, externalRef }:{
  clientId: string; date: string; time?: string; notesId?: string; externalRef?: string;
}) {
  // simplistic upsert by clientId+date
  const existing = await db.select().from(appointments)
    .where(and(eq(appointments.clientId, clientId), eq(appointments.date, date)));
  if (existing) {
    const [row] = await db.update(appointments)
      .set({ time: time ?? existing.time, notesId: notesId ?? existing.notesId, externalRef: externalRef ?? existing.externalRef })
      .where(eq(appointments.id, existing.id)).returning();
    return row;
  }
  const [row] = await db.insert(appointments).values({ clientId, date, time, notesId, externalRef }).returning();
  return row;
}

export async function upsertEdges(documentId: string, edges: {from:string;to:string;relation:string;weight?:number}[]) {
  // de-duplicate by (documentId, from, to, relation)
  // naive approach: fetch and filter; optimize later
  const existing = await db.select().from(semanticEdges).where(eq(semanticEdges.documentId, documentId));
  const key = (e:any)=>`${e.from}|${e.to}|${e.relation}`;
  const existingKeys = new Set(existing.map(key));
  const toInsert = edges.filter(e => !existingKeys.has(key(e)));
  if (!toInsert.length) return [];
  const rows = await db.insert(semanticEdges).values(toInsert.map(e => ({ documentId, ...e }))).returning();
  return rows;
}

export async function listAIResultsForClient(clientId: string, from?: string, to?: string) {
  // Simplified: join documents -> ai_document_results
  const docs = await db.select().from(documents).where(eq(documents.clientId, clientId));
  const docIds = new Set(docs.map(d => d.id));
  if (!docIds.size) return [];
  const results = await db.select().from(aiDocumentResults);
  return results.filter(r => docIds.has(r.documentId));
}

3) PDF service: server/services/pdf.ts
Wraps pdf-parse with hardened fallback.

TypeScript
// server/services/pdf.ts
import fs from "fs/promises";
import path from "path";
import pdfParse from "pdf-parse"; // ensure dependency or dynamic import
import { getDocument, updateDocumentParsed } from "../storage-extensions";

function cleanFallback(raw: Buffer | string) {
  const text = (typeof raw === "string" ? raw : raw.toString("utf-8"))
    .replace(/\r/g, "\n")
    .replace(/(?:obj|endobj|stream|endstream|xref|trailer|startxref)[\s\S]*?/gi, " ")
    .replace(/[^\S\r\n]+/g, " ")
    .replace(/\n{3,}/g, "\n\n")
    .trim();
  return text;
}

export async function parsePDF(documentId: string) {
  const doc = await getDocument(documentId);
  if (!doc) throw new Error(`Document not found: ${documentId}`);
  const filePath = doc.meta?.filePath as string | undefined;
  if (!filePath) throw new Error(`Missing file path for document ${documentId}`);

  let text = "";
  let meta: any = { method: "pdf-parse" };
  try {
    const data = await fs.readFile(filePath);
    const parsed = await pdfParse(data);
    text = (parsed.text || "").trim();
    if (text.length c.text).join("\n") : json.content?.?.text ?? "";
    return { raw: content, model: "anthropic:claude-3-5-sonnet-20240620" };
  }
}

function tryParseJSON(raw: string) {
  // Strip code fences if present
  const trimmed = raw.trim().replace(/^```json\s*/i, "").replace(/```
  return JSON.parse(trimmed);
}

export async function processDocumentWithAI(documentId: string) {
  const doc = await getDocument(documentId);
  if (!doc?.text) throw new Error(`Document ${documentId} not parsed or empty`);

  const prompt = buildPrompt(doc.text);
  let parsed: any;
  let model = "";
  try {
    const { raw, model: usedModel } = await callLLM(prompt);
    model = usedModel;
    parsed = tryParseJSON(raw);
  } catch (e) {
    // retry once with explicit JSON-only reminder
    const retry = buildPrompt(doc.text + "\n\nRespond with JSON only.");
    const { raw, model: usedModel } = await callLLM(retry);
    model = usedModel;
    parsed = tryParseJSON(raw);
  }

  const result = ResultSchema.parse({ ...parsed, documentId });
  const entities = result.entities ?? {};
  const extractions = result.extractions ?? {};
  const confidence = result.confidence ?? 0;
  const summary = result.summary ?? "";
  const recommendations = result.recommendations ?? [];
  const edges = result.semanticEdges ?? [];

  // persist AI results
  const saved = await saveAIResult({
    documentId, promptId: PROMPT_ID, model, entities, extractions, summary, recommendations, confidence
  });

  // upsert appointment link if entities.appointment exists and doc has clientId
  if (doc.clientId && entities.appointment?.date) {
    await upsertAppointment({
      clientId: doc.clientId,
      date: entities.appointment.date!,
      time: entities.appointment.time,
      notesId: saved.id,
    });
  }

  // upsert edges
  if (edges?.length) {
    await upsertEdges(documentId, edges);
  }

  return { saved, edgesCount: edges.length };
}

5) Semantic service: server/services/semantic.ts
Query/recall helpers.

TypeScript
// server/services/semantic.ts
import { db } from "../data/db";
import { semanticEdges, documents, aiDocumentResults } from "../../shared/schema";
import { eq, and, between } from "drizzle-orm";

export async function getGraph(clientId: string, range?: {from?: string; to?: string}) {
  const docs = await db.select().from(documents).where(eq(documents.clientId, clientId));
  const ids = docs.map(d => d.id);
  if (!ids.length) return [];
  const edges = await db.select().from(semanticEdges);
  const byDoc = new Map(edges.filter(e => ids.includes(e.documentId)).map(e => [e.id, e]));
  return Array.from(byDoc.values());
}

export async function recall(clientId: string, q: string) {
  const docs = await db.select().from(documents).where(eq(documents.clientId, clientId));
  const ids = docs.map(d => d.id);
  if (!ids.length) return [];
  const edges = await db.select().from(semanticEdges);
  return edges.filter(e => ids.includes(e.documentId) && (e.from.includes(q) || e.to.includes(q)));
}

6) Documents routes: server/routes/documents.ts
Multipart upload, parse, batch processing.

TypeScript
// server/routes/documents.ts
import express from "express";
import multer from "multer";
import path from "path";
import fs from "fs/promises";
import { createDocument, getDocument } from "../storage-extensions";
import { parsePDF } from "../services/pdf";
import { processDocumentWithAI } from "../services/ai";
import { getAIResult } from "../storage-extensions";

const upload = multer({ dest: "uploads/" });
export const documentsRouter = express.Router();

documentsRouter.post("/upload", upload.array("files"), async (req, res) => {
  try {
    const { clientId, appointmentDate } = req.body;
    if (!clientId || !appointmentDate) return res.status(400).json({ error: "clientId and appointmentDate required" });

    const files = (req.files as Express.Multer.File[]) || [];
    const uploaded = [];
    for (const f of files) {
      const meta = { filePath: path.resolve(f.path), originalName: f.originalname, size: f.size };
      const doc = await createDocument({
        clientId, appointmentDate, filename: f.originalname, mimeType: f.mimetype, meta
      });
      uploaded.push({ documentId: doc.id, filename: f.originalname, status: "stored" });
    }
    res.json({ uploaded });
  } catch (e: any) {
    res.status(500).json({ error: String(e) });
  }
});

documentsRouter.post("/parse", async (req, res) => {
  try {
    const { documentId } = req.body;
    if (!documentId) return res.status(400).json({ error: "documentId required" });

    const doc = await getDocument(documentId);
    if (!doc) return res.status(404).json({ error: "Not found" });
    if (doc.status === "parsed" && (doc.text?.length || 0) > 100) {
      return res.json({ documentId, status: "parsed", charCount: doc.text.length, skipped: true });
    }

    const { text, meta, qualityScore } = await parsePDF(documentId);
    res.json({ documentId, status: "parsed", charCount: text.length, qualityScore, meta });
  } catch (e: any) {
    res.status(500).json({ error: String(e) });
  }
});

documentsRouter.post("/process-batch", async (req, res) => {
  try {
    const { clientId, appointmentDate, documentIds, promptId = "care_notes_v1", force = false } = req.body;
    if (!clientId || !appointmentDate || !Array.isArray(documentIds)) {
      return res.status(400).json({ error: "clientId, appointmentDate, documentIds required" });
    }
    const results: any[] = [];
    for (const id of documentIds) {
      try {
        const doc = await getDocument(id);
        if (!doc) { results.push({ documentId: id, error: "not found" }); continue; }
        if ((doc.status !== "parsed" || (doc.text?.length || 0)  {
  try {
    const { documentId } = req.body;
    if (!documentId) return res.status(400).json({ error: "documentId required" });
    const r = await processDocumentWithAI(documentId);
    res.json(r);
  } catch (e: any) {
    res.status(500).json({ error: String(e) });
  }
});

aiRouter.get("/results", async (req, res) => {
  try {
    const { clientId, from, to } = req.query as any;
    if (!clientId) return res.status(400).json({ error: "clientId required" });
    const rows = await listAIResultsForClient(clientId, from, to);
    res.json({ results: rows });
  } catch (e: any) {
    res.status(500).json({ error: String(e) });
  }
});

8) Semantic routes: server/routes/semantic.ts
Graph and recall.

TypeScript
// server/routes/semantic.ts
import express from "express";
import { getGraph, recall } from "../services/semantic";

export const semanticRouter = express.Router();

semanticRouter.get("/graph", async (req, res) => {
  try {
    const { clientId, from, to } = req.query as any;
    if (!clientId) return res.status(400).json({ error: "clientId required" });
    const rows = await getGraph(clientId, { from, to });
    res.json({ edges: rows });
  } catch (e: any) {
    res.status(500).json({ error: String(e) });
  }
});

semanticRouter.get("/recall", async (req, res) => {
  try {
    const { clientId, q } = req.query as any;
    if (!clientId || !q) return res.status(400).json({ error: "clientId and q required" });
    const rows = await recall(clientId, q);
    res.json({ matches: rows });
  } catch (e: any) {
    res.status(500).json({ error: String(e) });
  }
});

9) Client pages/components
Upload, Results, Client detail, plus small components.

TypeScript
// client/src/components/documents/UploadPanel.tsx
import React, { useState } from "react";

export function UploadPanel() {
  const [clientId, setClientId] = useState("");
  const [appointmentDate, setAppointmentDate] = useState("");
  const [files, setFiles] = useState(null);
  const [status, setStatus] = useState([]);

  async function handleSubmit(e: React.FormEvent) {
    e.preventDefault();
    if (!clientId || !appointmentDate || !files?.length) return;

    const form = new FormData();
    form.append("clientId", clientId);
    form.append("appointmentDate", appointmentDate);
    Array.from(files).forEach(f => form.append("files", f));

    const up = await fetch("/api/documents/upload", { method: "POST", body: form }).then(r => r.json());
    const ids = up.uploaded?.map((u:any)=>u.documentId) || [];
    setStatus(s => [...s, { step: "uploaded", ids }]);

    // parse each
    const parsed: string[] = [];
    for (const id of ids) {
      const r = await fetch("/api/documents/parse", { method: "POST", headers: {"Content-Type":"application/json"}, body: JSON.stringify({ documentId: id }) }).then(r => r.json());
      parsed.push(id);
    }
    setStatus(s => [...s, { step: "parsed", ids: parsed }]);

    // AI process batch
    const batch = await fetch("/api/documents/process-batch", {
      method: "POST",
      headers: {"Content-Type":"application/json"},
      body: JSON.stringify({ clientId, appointmentDate, documentIds: ids, promptId: "care_notes_v1" })
    }).then(r => r.json());
    setStatus(s => [...s, { step: "ai", result: batch }]);
  }

  return (
    
      setClientId(e.target.value)} />
      setAppointmentDate(e.target.value)} />
      setFiles(e.target.files)} />
      Upload & Process
      {JSON.stringify(status, null, 2)}
    
  );
}

TypeScript
// client/src/components/results/AIResultCard.tsx
import React from "react";

export function AIResultCard({ result }: { result: any }) {
  if (!result) return null;
  return (
    
      Model: {result.model}
      Summary
      {result.summary}
      
        
          Diagnoses
          
            {(result.extractions?.diagnoses ?? []).map((d:any,i:number)=>{d.code ? `${d.code} - `:""}{d.label})}
          
        
        
          Medications
          
            {(result.extractions?.medications ?? []).map((m:any,i:number)=>{m.name} {m.dose||""} {m.freq||""})}
          
        
        
          Symptoms
          
            {(result.extractions?.symptoms ?? []).map((s:string,i:number)=>{s})}
          
        
        
          Risk Factors
          
            {(result.extractions?.risk_factors ?? []).map((s:string,i:number)=>{s})}
          
        
      
      
        Recommendations
        
          {(result.recommendations ?? []).map((r:string,i:number)=>{r})}
        
      
      Confidence: {result.confidence ?? 0}%
    
  );
}

TypeScript
// client/src/components/semantic/EdgeList.tsx
import React from "react";
export function EdgeList({ edges }:{ edges: any[] }) {
  if (!edges?.length) return No edges.;
  return (
    
      {edges.map((e:any)=>(
        {e.from} —[{e.relation}]→ {e.to} {typeof e.weight==="number" ? `(${e.weight})` : ""}
      ))}
    
  );
}

TypeScript
// client/src/components/semantic/GraphPreview.tsx
import React from "react";
import { EdgeList } from "./EdgeList";
export function GraphPreview({ clientId }:{ clientId: string }) {
  const [edges, setEdges] = React.useState([]);
  const [q, setQ] = React.useState("");
  const [matches, setMatches] = React.useState([]);
  React.useEffect(()=>{ (async()=>{
    if (!clientId) return;
    const r = await fetch(`/api/semantic/graph?clientId=${encodeURIComponent(clientId)}`).then(r=>r.json());
    setEdges(r.edges || []);
  })(); }, [clientId]);
  async function handleRecall(e: React.FormEvent) {
    e.preventDefault();
    const r = await fetch(`/api/semantic/recall?clientId=${encodeURIComponent(clientId)}&q=${encodeURIComponent(q)}`).then(r=>r.json());
    setMatches(r.matches || []);
  }
  return (
    
      Semantic Graph
      
      
        setQ(e.target.value)} />
        Search
      
      {matches.length>0 && (
        
          Recall Matches
          
        
      )}
    
  );
}

TypeScript
// client/src/pages/DocumentsUpload.tsx
import React from "react";
import { UploadPanel } from "../components/documents/UploadPanel";
export default function DocumentsUpload() {
  return (
    
      Care Notes Upload & Process
      
    
  );
}

TypeScript
// client/src/pages/CareNotesResults.tsx
import React, { useEffect, useState } from "react";
import { AIResultCard } from "../components/results/AIResultCard";

export default function CareNotesResults() {
  const [clientId, setClientId] = useState("");
  const [results, setResults] = useState([]);
  async function fetchResults() {
    if (!clientId) return;
    const r = await fetch(`/api/ai/results?clientId=${encodeURIComponent(clientId)}`).then(r=>r.json());
    setResults(r.results || []);
  }
  useEffect(()=>{ fetchResults(); }, [clientId]);
  return (
    
      AI Results
      setClientId(e.target.value)} />
      
        {results.map(r => )}
      
    
  );
}

TypeScript
// client/src/pages/ClientDetail.tsx
import React, { useState } from "react";
import { GraphPreview } from "../components/semantic/GraphPreview";

export default function ClientDetail() {
  const [clientId, setClientId] = useState("");
  return (
    
      Client Detail
      setClientId(e.target.value)} />
      {clientId && }
    
  );
}

10) Server registration
Ensure you mount new routers in your server bootstrap (e.g., server/index.ts):

TypeScript
// server/index.ts (snippet)
import express from "express";
import { documentsRouter } from "./routes/documents";
import { aiRouter } from "./routes/ai";
import { semanticRouter } from "./routes/semantic";

const app = express();
app.use(express.json({ limit: "10mb" }));
app.use("/api/documents", documentsRouter);
app.use("/api/ai", aiRouter);
app.use("/api/semantic", semanticRouter);

// ...existing bootstrap and listen

11) Acceptance criteria (agent checklist)
- Upload → returns documentIds; files saved and document rows created
- Parse → documents.text populated (>100 chars for typical PDFs); status=parsed
- AI process → ai_document_results row created; entities/extractions/summary/recommendations/confidence persisted; appointment upserted if entities.appointment present
- Semantic edges → 3+ edges per typical note, de-duplicated by (documentId, from, to, relation)
- Longitudinal → /api/ai/results and /api/semantic/graph/recall power ClientDetail and CareNotesResults pages
- Idempotency → parse/AI skipped if already done unless force=true; batch returns per-doc statuses
- Error handling → every failure returns JSON with error; logs single concise line per step

Notes/TODOs for the agent
- Ensure pdf-parse is installed; if not, adjust dynamic import or keep fallback only
- Wire db import in storage-extensions.ts to your actual db client
- Add proper auth middleware if needed on routes
- Optionally add rate limits/queueing for AI calls

If you want, I can also provide a single monolithic “patch” format that concatenates these into unified diffs for your exact repo.

[1] https://replit.com/@jonathanprocter/CareNotesAI